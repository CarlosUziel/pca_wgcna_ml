{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Sandbox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path: str = \"../src\"\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.functional_analysis.orgdb import OrgDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCGA_PRAD_SU2C_PCF_GSE221601_ROOT: Path = Path(\n",
    "    \"/media/ssd/Perez/storage/TCGA_PRAD_SU2C_PCF_GSE221601\"\n",
    ")\n",
    "GOIS: Iterable[str] = (\"TPX2\", \"EZH2\", \"TROAP\", \"COX1\", \"UHRF1\")\n",
    "ORG_DB: OrgDB = OrgDB(\"Homo sapiens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For all integrative analysis results, find appereances of genes of interest."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "relevant_files = {\n",
    "    goi: {\"BOTH\": [], \"HSPC_vs_PRIM\": [], \"MCRPC_vs_HSPC\": []} for goi in GOIS\n",
    "}\n",
    "\n",
    "for int_analysis_file in (\n",
    "    TCGA_PRAD_SU2C_PCF_GSE221601_ROOT / \"integrative_analysis\"\n",
    ").rglob(\"*.csv\"):\n",
    "    if \"pathway\" in int_analysis_file.name:\n",
    "        continue\n",
    "\n",
    "    results_df = pd.read_csv(int_analysis_file)\n",
    "    if \"SYMBOL\" not in results_df.columns:\n",
    "        continue\n",
    "\n",
    "    hspc_vs_prim_col = next(\n",
    "        col for col in results_df.columns if col.startswith(\"HSPC_vs_PRIM\")\n",
    "    )\n",
    "    hspc_vs_prim_col_idx = results_df.columns.get_loc(hspc_vs_prim_col)\n",
    "    mcrpc_vs_hspc_col = next(\n",
    "        col for col in results_df.columns if col.startswith(\"MCRPC_vs_HSPC\")\n",
    "    )\n",
    "    mcrpc_vs_hspc_col_idx = results_df.columns.get_loc(mcrpc_vs_hspc_col)\n",
    "\n",
    "    for goi in GOIS:\n",
    "        if goi in results_df[\"SYMBOL\"].tolist():\n",
    "            goi_rows = results_df[results_df[\"SYMBOL\"] == goi].squeeze()\n",
    "            if (\n",
    "                goi_rows.iloc[hspc_vs_prim_col_idx]\n",
    "                & goi_rows.iloc[mcrpc_vs_hspc_col_idx]\n",
    "            ):\n",
    "                relevant_files[goi][\"BOTH\"].append(str(int_analysis_file))\n",
    "            if (\n",
    "                goi_rows.iloc[hspc_vs_prim_col_idx]\n",
    "                & ~goi_rows.iloc[mcrpc_vs_hspc_col_idx]\n",
    "            ):\n",
    "                relevant_files[goi][\"HSPC_vs_PRIM\"].append(str(int_analysis_file))\n",
    "            if (\n",
    "                ~goi_rows.iloc[hspc_vs_prim_col_idx]\n",
    "                & goi_rows.iloc[mcrpc_vs_hspc_col_idx]\n",
    "            ):\n",
    "                relevant_files[goi][\"MCRPC_vs_HSPC\"].append(str(int_analysis_file))\n",
    "\n",
    "print(relevant_files)\n",
    "with open(\"relevant_files.json\", \"w\") as f:\n",
    "    json.dump(relevant_files, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy original tar counts files to analysis directory"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "STAR_ROOT: Path = Path(\"/rawdata/GSE221601/mapping/star\")\n",
    "ANALYSIS_ROOT: Path = Path(\"/media/ssd/Perez/storage/GSE221601/data\")\n",
    "STAR_ORIGINAL_COUNTS_PATH: Path = ANALYSIS_ROOT / \"star_original_counts\"\n",
    "STAR_ORIGINAL_COUNTS_PATH.mkdir(exist_ok=True, parents=True)\n",
    "STAR_UNSTRANDED_COUNTS_PATH: Path = ANALYSIS_ROOT / \"star_unstranded_counts\"\n",
    "STAR_UNSTRANDED_COUNTS_PATH.mkdir(exist_ok=True, parents=True)\n",
    "STAR_FIRST_READ_STRAND_COUNTS_PATH: Path = (\n",
    "    ANALYSIS_ROOT / \"star_first_read_strand_counts\"\n",
    ")\n",
    "STAR_FIRST_READ_STRAND_COUNTS_PATH.mkdir(exist_ok=True, parents=True)\n",
    "STAR_SECOND_READ_STRAND_COUNTS_PATH: Path = (\n",
    "    ANALYSIS_ROOT / \"star_second_read_strand_counts\"\n",
    ")\n",
    "STAR_SECOND_READ_STRAND_COUNTS_PATH.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "for tab_file in STAR_ROOT.rglob(\"ReadsPerGene.out.tab\"):\n",
    "    parent_dir_name = tab_file.parent.name\n",
    "    destination_file = STAR_ORIGINAL_COUNTS_PATH / f\"{parent_dir_name}.tab\"\n",
    "    destination_file.write_bytes(tab_file.read_bytes())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "clean_star_counts(\n",
    "    star_path=STAR_ROOT,\n",
    "    star_counts_path=STAR_UNSTRANDED_COUNTS_PATH,\n",
    "    subset_col=1,\n",
    ")\n",
    "clean_star_counts(\n",
    "    star_path=STAR_ROOT,\n",
    "    star_counts_path=STAR_FIRST_READ_STRAND_COUNTS_PATH,\n",
    "    subset_col=2,\n",
    ")\n",
    "clean_star_counts(\n",
    "    star_path=STAR_ROOT,\n",
    "    star_counts_path=STAR_SECOND_READ_STRAND_COUNTS_PATH,\n",
    "    subset_col=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate LRT deseq files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "lrt_files = list(\n",
    "    Path(\"/media/ssd/Perez/storage/PCTA_WCDT_GSE221601_LRT/deseq2\").glob(\n",
    "        \"*deseq_results.csv\"\n",
    "    )\n",
    ")\n",
    "for lrt_file in lrt_files:\n",
    "    print(lrt_file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "for lrt_file in lrt_files:\n",
    "    print(\"Processing file:\", lrt_file)\n",
    "    lrt_results = pd.read_csv(lrt_file, index_col=0)\n",
    "\n",
    "    lrt_results_annot = annotate_deseq_result(pd_df_to_rpy2_df(lrt_results), ORG_DB)\n",
    "\n",
    "    lrt_results_annot = (\n",
    "        lrt_results_annot[\n",
    "            ~lrt_results_annot[\"ENTREZID\"].str.contains(\"/\", na=False)\n",
    "            | ~lrt_results_annot[\"SYMBOL\"].str.contains(\"/\", na=False)\n",
    "        ]\n",
    "        .dropna(subset=[\"ENTREZID\", \"SYMBOL\"])\n",
    "        .drop_duplicates(subset=[\"ENTREZID\", \"SYMBOL\"], keep=False)\n",
    "    )\n",
    "\n",
    "    lrt_results_annot.to_csv(lrt_file.with_name(lrt_file.stem + \"_unique.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Correction PCA figures"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "counts_files = [\n",
    "    \"raw_counts.csv\",\n",
    "    \"all_counts_batch_corrected_v1.csv\",\n",
    "    \"all_counts_batch_corrected_v2.csv\",\n",
    "    \"all_counts_batch_corrected_v3.csv\",\n",
    "]\n",
    "root_path = Path(\"/media/ssd/Perez/storage/PCTA_WCDT_GSE221601/data\")\n",
    "manuscript_figures_path = root_path.parent / \"manuscript_figures\"\n",
    "manuscript_figures_path.mkdir(exist_ok=True, parents=True)\n",
    "CONTRASTS_LEVELS_COLORS = {\n",
    "    \"mcrpc\": \"#8B3A3A\",\n",
    "    \"prim\": \"#4A708B\",\n",
    "    \"hspc\": \"#8B008B\",\n",
    "    \"norm\": \"#9ACD32\",\n",
    "}\n",
    "annot_df = pd.read_csv(root_path / \"samples_annotation.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "for i, count_file in enumerate(counts_files):\n",
    "    counts_df = pd.read_csv(root_path / count_file, index_col=0)\n",
    "    vst_df = rpy2_df_to_pd_df(\n",
    "        vst_transform(ro.r(\"as.matrix\")(pd_df_to_rpy2_df(counts_df)))\n",
    "    )\n",
    "\n",
    "    pca_corrected = PCA(n_components=2)\n",
    "    pca_result_corrected = pca_corrected.fit_transform(vst_df.T)\n",
    "\n",
    "    pca_df_corrected = pd.DataFrame(\n",
    "        data=pca_result_corrected,\n",
    "        columns=[\"PC1\", \"PC2\"],\n",
    "        index=vst_df.columns,\n",
    "    )\n",
    "    pca_df_corrected[\"sample_type\"] = annot_df.loc[vst_df.columns, \"sample_type\"].values\n",
    "    pca_df_corrected[\"dataset\"] = annot_df.loc[vst_df.columns, \"dataset\"].values\n",
    "    pca_df_corrected[\"library_type\"] = annot_df.loc[\n",
    "        vst_df.columns, \"library_type\"\n",
    "    ].values\n",
    "    explained_variance = pca_corrected.explained_variance_ratio_\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(\n",
    "        x=\"PC1\",\n",
    "        y=\"PC2\",\n",
    "        hue=\"sample_type\",\n",
    "        style=\"library_type\",\n",
    "        data=pca_df_corrected,\n",
    "        palette=CONTRASTS_LEVELS_COLORS,\n",
    "    )\n",
    "    if i == 0:\n",
    "        plt.title(\"PCA of RNA-Seq Expression Data (VST)\")\n",
    "    else:\n",
    "        plt.title(f\"PCA of Batch-Corrected RNA-Seq Expression Data (VST) - Round {i}\")\n",
    "    plt.xlabel(f\"Principal Component 1 ({explained_variance[0] * 100:.2f}%)\")\n",
    "    plt.ylabel(f\"Principal Component 2 ({explained_variance[1] * 100:.2f}%)\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(manuscript_figures_path / f\"{Path(count_file).stem}_pca.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT: Path = Path(\n",
    "    \"/media/ssd/Perez/storage/PCTA_WCDT_GSE221601_FILTERED/ml_classifiers\"\n",
    ")\n",
    "test_scores = dict()\n",
    "\n",
    "for test_scores_file in ROOT.rglob(\"*test_scores.csv\"):\n",
    "    model_type = test_scores_file.parents[2].stem\n",
    "    if \"prim_vs_norm\" in test_scores_file.parents[3].stem:\n",
    "        test_scores[(\"prim_vs_norm\", model_type)] = pd.read_csv(\n",
    "            test_scores_file, index_col=0\n",
    "        ).agg([\"mean\", \"std\"])\n",
    "    elif \"hspc_vs_prim\" in test_scores_file.parents[3].stem:\n",
    "        test_scores[(\"hspc_vs_norm\", model_type)] = pd.read_csv(\n",
    "            test_scores_file, index_col=0\n",
    "        ).agg([\"mean\", \"std\"])\n",
    "    elif \"mcrpc_vs_hspc\" in test_scores_file.parents[3].stem:\n",
    "        test_scores[(\"mcrpc_vs_hspc\", model_type)] = pd.read_csv(\n",
    "            test_scores_file, index_col=0\n",
    "        ).agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRASTS_NAMES_MAP = {\n",
    "    \"prim_vs_norm\": \"prim/norm\",\n",
    "    \"hspc_vs_norm\": \"hspc/prim\",\n",
    "    \"mcrpc_vs_hspc\": \"mcrpc/hspc\",\n",
    "}\n",
    "MODEL_NAMES_MAP = {\n",
    "    \"decision_tree\": \"Decision Tree\",\n",
    "    \"random_forest\": \"Random Forest\",\n",
    "    \"light_gbm\": \"LightGBM\",\n",
    "}\n",
    "sorted_indices = product(CONTRASTS_NAMES_MAP.values(), MODEL_NAMES_MAP.values())\n",
    "records = []\n",
    "\n",
    "# 2. Iterate through dictionary and reshape data\n",
    "for (contrast, model), df in test_scores.items():\n",
    "    # Extract mean and std rows\n",
    "    mean_row = df.loc[\"mean\"]\n",
    "    std_row = df.loc[\"std\"]\n",
    "\n",
    "    # Create record with hierarchical structure\n",
    "    for metric in df.columns:\n",
    "        records.append(\n",
    "            {\n",
    "                \"contrast\": CONTRASTS_NAMES_MAP[contrast],\n",
    "                \"model\": MODEL_NAMES_MAP[model],\n",
    "                \"metric\": metric,\n",
    "                \"mean\": mean_row[metric],\n",
    "                \"std\": std_row[metric],\n",
    "            }\n",
    "        )\n",
    "\n",
    "# 3. Convert to DataFrame and reshape\n",
    "df = pd.DataFrame(records)\n",
    "df_pivot = (\n",
    "    df.pivot_table(\n",
    "        index=[\"contrast\", \"model\"], columns=\"metric\", values=[\"mean\", \"std\"]\n",
    "    )\n",
    "    .round(4)\n",
    "    .loc[sorted_indices]\n",
    ")\n",
    "\n",
    "display(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.groupby(level=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
